{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online_Shoppers_Purchasing_Intention_Dataset_Data_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('online_shoppers_intention.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some basic info for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      "Administrative             12330 non-null int64\n",
      "Administrative_Duration    12330 non-null float64\n",
      "Informational              12330 non-null int64\n",
      "Informational_Duration     12330 non-null float64\n",
      "ProductRelated             12330 non-null int64\n",
      "ProductRelated_Duration    12330 non-null float64\n",
      "BounceRates                12330 non-null float64\n",
      "ExitRates                  12330 non-null float64\n",
      "PageValues                 12330 non-null float64\n",
      "SpecialDay                 12330 non-null float64\n",
      "Month                      12330 non-null object\n",
      "OperatingSystems           12330 non-null int64\n",
      "Browser                    12330 non-null int64\n",
      "Region                     12330 non-null int64\n",
      "TrafficType                12330 non-null int64\n",
      "VisitorType                12330 non-null object\n",
      "Weekend                    12330 non-null bool\n",
      "Revenue                    12330 non-null bool\n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             0\n",
       "Administrative_Duration    0\n",
       "Informational              0\n",
       "Informational_Duration     0\n",
       "ProductRelated             0\n",
       "ProductRelated_Duration    0\n",
       "BounceRates                0\n",
       "ExitRates                  0\n",
       "PageValues                 0\n",
       "SpecialDay                 0\n",
       "Month                      0\n",
       "OperatingSystems           0\n",
       "Browser                    0\n",
       "Region                     0\n",
       "TrafficType                0\n",
       "VisitorType                0\n",
       "Weekend                    0\n",
       "Revenue                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing data in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.315166</td>\n",
       "      <td>80.818611</td>\n",
       "      <td>0.503569</td>\n",
       "      <td>34.472398</td>\n",
       "      <td>31.731468</td>\n",
       "      <td>1194.746220</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>5.889258</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>2.124006</td>\n",
       "      <td>2.357097</td>\n",
       "      <td>3.147364</td>\n",
       "      <td>4.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.321784</td>\n",
       "      <td>176.779107</td>\n",
       "      <td>1.270156</td>\n",
       "      <td>140.749294</td>\n",
       "      <td>44.475503</td>\n",
       "      <td>1913.669288</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>18.568437</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.911325</td>\n",
       "      <td>1.717277</td>\n",
       "      <td>2.401591</td>\n",
       "      <td>4.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>184.137500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>598.936905</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.256250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1464.157213</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12330.000000             12330.000000   12330.000000   \n",
       "mean         2.315166                80.818611       0.503569   \n",
       "std          3.321784               176.779107       1.270156   \n",
       "min          0.000000                 0.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 7.500000       0.000000   \n",
       "75%          4.000000                93.256250       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12330.000000    12330.000000             12330.000000   \n",
       "mean                34.472398       31.731468              1194.746220   \n",
       "std                140.749294       44.475503              1913.669288   \n",
       "min                  0.000000        0.000000                 0.000000   \n",
       "25%                  0.000000        7.000000               184.137500   \n",
       "50%                  0.000000       18.000000               598.936905   \n",
       "75%                  0.000000       38.000000              1464.157213   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
       "mean       0.022191      0.043073      5.889258      0.061427   \n",
       "std        0.048488      0.048597     18.568437      0.198917   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003112      0.025156      0.000000      0.000000   \n",
       "75%        0.016813      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
       "mean           2.124006      2.357097      3.147364      4.069586  \n",
       "std            0.911325      1.717277      2.401591      4.025169  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of Possible values\n",
      "Administrative :  27\n",
      "Administrative_Duration :  3335\n",
      "Informational :  17\n",
      "Informational_Duration :  1258\n",
      "ProductRelated :  311\n",
      "ProductRelated_Duration :  9551\n",
      "BounceRates :  1872\n",
      "ExitRates :  4777\n",
      "PageValues :  2704\n",
      "SpecialDay :  6\n",
      "Month :  10\n",
      "OperatingSystems :  8\n",
      "Browser :  13\n",
      "Region :  9\n",
      "TrafficType :  20\n",
      "VisitorType :  3\n",
      "Weekend :  2\n",
      "Revenue :  2\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of Possible values')\n",
    "for col in data.columns:\n",
    "    print(col,': ',len(set(data[col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, change weekend and Revenue in numeric notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weekend'] = data['Weekend']*1\n",
    "data['Revenue'] = data['Revenue']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Revenue\n",
       "0    10422\n",
       "1     1908\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Revenue').size() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So less than 2000 records with revenues in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Revenue</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aug</th>\n",
       "      <td>357</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec</th>\n",
       "      <td>1511</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul</th>\n",
       "      <td>366</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>259</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>1715</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>2999</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nov</th>\n",
       "      <td>2238</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct</th>\n",
       "      <td>434</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep</th>\n",
       "      <td>362</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Revenue     0    1\n",
       "Month             \n",
       "Aug       357   76\n",
       "Dec      1511  216\n",
       "Feb       181    3\n",
       "Jul       366   66\n",
       "June      259   29\n",
       "Mar      1715  192\n",
       "May      2999  365\n",
       "Nov      2238  760\n",
       "Oct       434  115\n",
       "Sep       362   86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot_table(index='Month',columns='Revenue',values='Weekend',aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nov has the largest number of purchases while Feb has the smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Revenue</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisitorType</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New_Visitor</th>\n",
       "      <td>1272</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Returning_Visitor</th>\n",
       "      <td>9081</td>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Revenue               0     1\n",
       "VisitorType                  \n",
       "New_Visitor        1272   422\n",
       "Other                69    16\n",
       "Returning_Visitor  9081  1470"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot_table(index='VisitorType',columns='Revenue',values='Weekend',aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most visitors are returning visitors. However, portion of purchase for new visitor is higher than returning visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heat map, there are some insights \n",
    "1. Administrative, Administrative_Duration, Informational, Informational_Duration, ProductRelated, and ProductRelated_Duration are correlated in a rather high degree. It is possible to do reduce the dimension of the dataset \n",
    "2. PageValues has the highest correlation with Revenue \n",
    "3. BounceRates and ExitRates have negative correlations with Revenue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since PageValues is positively correlated with Revenue, now a logistic regression is carried to study the effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.319902\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Revenue   No. Observations:                12330\n",
      "Model:                          Logit   Df Residuals:                    12328\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 24 Aug 2019   Pseudo R-squ.:                  0.2575\n",
      "Time:                        11:48:55   Log-Likelihood:                -3944.4\n",
      "converged:                       True   LL-Null:                       -5312.4\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.4164      0.034    -70.199      0.000      -2.484      -2.349\n",
      "PageValues     0.0890      0.002     38.021      0.000       0.084       0.094\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X = data['PageValues']\n",
    "y = data['Revenue']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a higher PageValues will increase the probability of having a purchase as the p-value is less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, Administrative, Administrative_Duration, Informational, Informational_Duration, ProductRelated, and ProductRelated_Duration are all correlated together. As a result, only on variable is kept for further analysis (Administrative_Duration)\n",
    "<br>\n",
    "This also applies to BounceRates and ExitRates (BounceRates is kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop(['Administrative', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'ExitRates'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative_Duration  BounceRates  PageValues  SpecialDay Month  \\\n",
       "0                      0.0         0.20         0.0         0.0   Feb   \n",
       "1                      0.0         0.00         0.0         0.0   Feb   \n",
       "2                      0.0         0.20         0.0         0.0   Feb   \n",
       "3                      0.0         0.05         0.0         0.0   Feb   \n",
       "4                      0.0         0.02         0.0         0.0   Feb   \n",
       "\n",
       "   OperatingSystems  Browser  Region  TrafficType        VisitorType  Weekend  \\\n",
       "0                 1        1       1            1  Returning_Visitor        0   \n",
       "1                 2        2       1            2  Returning_Visitor        0   \n",
       "2                 4        1       9            3  Returning_Visitor        0   \n",
       "3                 3        2       2            4  Returning_Visitor        0   \n",
       "4                 3        3       1            4  Returning_Visitor        1   \n",
       "\n",
       "   Revenue  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to include dummy variables for Month and VisitorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Month_dummy = pd.get_dummies(data2['Month'],drop_first=True)\n",
    "Visitor_dummy = pd.get_dummies(data2['VisitorType'],drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.drop(['Month','VisitorType'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data4 = pd.concat([data3,Month_dummy,Visitor_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Jul</th>\n",
       "      <th>June</th>\n",
       "      <th>Mar</th>\n",
       "      <th>May</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Other</th>\n",
       "      <th>Returning_Visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative_Duration  BounceRates  PageValues  SpecialDay  \\\n",
       "0                      0.0         0.20         0.0         0.0   \n",
       "1                      0.0         0.00         0.0         0.0   \n",
       "2                      0.0         0.20         0.0         0.0   \n",
       "3                      0.0         0.05         0.0         0.0   \n",
       "4                      0.0         0.02         0.0         0.0   \n",
       "\n",
       "   OperatingSystems  Browser  Region  TrafficType  Weekend  Revenue  ...  Feb  \\\n",
       "0                 1        1       1            1        0        0  ...    1   \n",
       "1                 2        2       1            2        0        0  ...    1   \n",
       "2                 4        1       9            3        0        0  ...    1   \n",
       "3                 3        2       2            4        0        0  ...    1   \n",
       "4                 3        3       1            4        1        0  ...    1   \n",
       "\n",
       "   Jul  June  Mar  May  Nov  Oct  Sep  Other  Returning_Visitor  \n",
       "0    0     0    0    0    0    0    0      0                  1  \n",
       "1    0     0    0    0    0    0    0      0                  1  \n",
       "2    0     0    0    0    0    0    0      0                  1  \n",
       "3    0     0    0    0    0    0    0      0                  1  \n",
       "4    0     0    0    0    0    0    0      0                  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to previous action, first is to carry out logistic regression to study the impact of each combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295840\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Revenue   No. Observations:                12330\n",
      "Model:                          Logit   Df Residuals:                    12309\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Sat, 24 Aug 2019   Pseudo R-squ.:                  0.3134\n",
      "Time:                        11:48:55   Log-Likelihood:                -3647.7\n",
      "converged:                       True   LL-Null:                       -5312.4\n",
      "                                        LLR p-value:                     0.000\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.8296      0.194     -9.444      0.000      -2.209      -1.450\n",
      "Administrative_Duration     0.0006      0.000      4.088      0.000       0.000       0.001\n",
      "BounceRates               -20.1059      2.358     -8.526      0.000     -24.728     -15.484\n",
      "PageValues                  0.0853      0.002     35.456      0.000       0.081       0.090\n",
      "SpecialDay                 -0.1314      0.234     -0.560      0.575      -0.591       0.328\n",
      "OperatingSystems           -0.0610      0.038     -1.608      0.108      -0.135       0.013\n",
      "Browser                     0.0376      0.018      2.042      0.041       0.002       0.074\n",
      "Region                     -0.0171      0.013     -1.319      0.187      -0.043       0.008\n",
      "TrafficType                -0.0007      0.008     -0.088      0.930      -0.017       0.015\n",
      "Weekend                     0.1272      0.070      1.810      0.070      -0.011       0.265\n",
      "Dec                        -0.6226      0.181     -3.441      0.001      -0.977      -0.268\n",
      "Feb                        -1.9311      0.630     -3.063      0.002      -3.167      -0.696\n",
      "Jul                         0.0753      0.218      0.346      0.729      -0.351       0.502\n",
      "June                       -0.3028      0.273     -1.109      0.267      -0.838       0.232\n",
      "Mar                        -0.5931      0.179     -3.321      0.001      -0.943      -0.243\n",
      "May                        -0.5997      0.173     -3.470      0.001      -0.939      -0.261\n",
      "Nov                         0.6105      0.162      3.778      0.000       0.294       0.927\n",
      "Oct                        -0.0306      0.201     -0.152      0.879      -0.425       0.364\n",
      "Sep                        -0.0014      0.211     -0.007      0.995      -0.415       0.412\n",
      "Other                      -0.6811      0.532     -1.281      0.200      -1.723       0.361\n",
      "Returning_Visitor          -0.2609      0.082     -3.165      0.002      -0.422      -0.099\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "x_variable = list(data4.columns.values)\n",
    "x_variable.remove('Revenue')\n",
    "\n",
    "X = data4[x_variable]\n",
    "y = data4['Revenue']\n",
    "X  = sm.add_constant(X)\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are some important variables that can be used to determine porchase \n",
    "<br>With positive influence: Administrative_Duration, PageValues, Browser, Weekend, Nov\n",
    "<br>With negative influence: BounceRates, Dec, Feb, Mar, May,Returning_Visitor\n",
    "<br><br>In general, behavoir while browsing, month, weekend, and times of buying can predict the purchase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to create a deep learning model to do the prediction \n",
    "<br>Based on results from logistic regression, only some variables will be used in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data[['Administrative_Duration','BounceRates','PageValues','Browser','Revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = pd.concat([data5,Month_dummy,Visitor_dummy],axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data5.drop('Revenue',axis=1)\n",
    "y=data5['Revenue']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. First is decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distree=DecisionTreeClassifier()\n",
    "distree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588807785888077"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1900,  155],\n",
       "       [ 193,  218]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=distree.predict(X_test)\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8714517437145174"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1942,  113],\n",
       "       [ 204,  207]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=knn.predict(X_test)\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems decision tree is better than KNN as decision tree can predict successful purchases more accurately so there will be no revenue loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create one more dataset for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to normalize dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_model(n_first,n_second,n_third):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_first,activation='relu',input_dim=X_train.shape[1])) \n",
    "    model.add(Dense(n_second,activation='relu')) \n",
    "    model.add(Dense(n_third, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['first_hidden','second_hidden','third_hidden','binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 1s 155us/step - loss: 0.4444 - val_loss: 0.3542\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.3207 - val_loss: 0.3117\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2896 - val_loss: 0.2966\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2747 - val_loss: 0.2876\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2648 - val_loss: 0.2817\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2580 - val_loss: 0.2763\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2527 - val_loss: 0.2720\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 48us/step - loss: 0.2496 - val_loss: 0.2730\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 40us/step - loss: 0.2475 - val_loss: 0.2685\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 38us/step - loss: 0.2458 - val_loss: 0.2694\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2443 - val_loss: 0.2686\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2426 - val_loss: 0.2701\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2424 - val_loss: 0.2656\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2411 - val_loss: 0.2651\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - ETA: 0s - loss: 0.240 - 0s 42us/step - loss: 0.2403 - val_loss: 0.2663\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2397 - val_loss: 0.2645\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 38us/step - loss: 0.2388 - val_loss: 0.2649\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 38us/step - loss: 0.2386 - val_loss: 0.2633\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 40us/step - loss: 0.2377 - val_loss: 0.2660\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2370 - val_loss: 0.2665\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2372 - val_loss: 0.2652\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2360 - val_loss: 0.2679\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 1s 77us/step - loss: 0.2358 - val_loss: 0.2641\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 1s 65us/step - loss: 0.2350 - val_loss: 0.2660\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 1s 69us/step - loss: 0.2347 - val_loss: 0.2637\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 1s 68us/step - loss: 0.2345 - val_loss: 0.2650\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 33us/step - loss: 0.2341 - val_loss: 0.2634\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2335 - val_loss: 0.2632\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2330 - val_loss: 0.2639\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2327 - val_loss: 0.2632\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 34us/step - loss: 0.2321 - val_loss: 0.2620\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2317 - val_loss: 0.2646\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2313 - val_loss: 0.2630\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 35us/step - loss: 0.2314 - val_loss: 0.2622\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2306 - val_loss: 0.2607\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 48us/step - loss: 0.2303 - val_loss: 0.2626\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 1s 70us/step - loss: 0.2304 - val_loss: 0.2628\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 43us/step - loss: 0.2301 - val_loss: 0.2698\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 34us/step - loss: 0.2304 - val_loss: 0.2638\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 34us/step - loss: 0.2293 - val_loss: 0.2679\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2289 - val_loss: 0.2625\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 44us/step - loss: 0.2289 - val_loss: 0.2621\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 44us/step - loss: 0.2285 - val_loss: 0.2618\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 39us/step - loss: 0.2288 - val_loss: 0.2637\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 38us/step - loss: 0.2279 - val_loss: 0.2652\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 39us/step - loss: 0.2280 - val_loss: 0.2633\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2285 - val_loss: 0.2615\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2276 - val_loss: 0.2688\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2273 - val_loss: 0.2621\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2277 - val_loss: 0.2611\n",
      "1973/1973 [==============================] - 0s 45us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 1s 184us/step - loss: 0.5275 - val_loss: 0.3767\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 33us/step - loss: 0.3136 - val_loss: 0.3013\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 31us/step - loss: 0.2717 - val_loss: 0.2823\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 32us/step - loss: 0.2582 - val_loss: 0.2739\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 31us/step - loss: 0.2503 - val_loss: 0.2729\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 31us/step - loss: 0.2462 - val_loss: 0.2666\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 31us/step - loss: 0.2427 - val_loss: 0.2637\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 32us/step - loss: 0.2397 - val_loss: 0.2637\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 31us/step - loss: 0.2384 - val_loss: 0.2629\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 32us/step - loss: 0.2374 - val_loss: 0.2590\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 32us/step - loss: 0.2362 - val_loss: 0.2602\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 32us/step - loss: 0.2350 - val_loss: 0.2580\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2336 - val_loss: 0.2600\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2334 - val_loss: 0.2620\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2330 - val_loss: 0.2584\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 44us/step - loss: 0.2322 - val_loss: 0.2627\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 45us/step - loss: 0.2322 - val_loss: 0.2606\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 40us/step - loss: 0.2313 - val_loss: 0.2565\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 39us/step - loss: 0.2308 - val_loss: 0.2580\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 45us/step - loss: 0.2302 - val_loss: 0.2570\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2297 - val_loss: 0.2591\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2295 - val_loss: 0.2596\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2289 - val_loss: 0.2602\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 0s 50us/step - loss: 0.2279 - val_loss: 0.2568\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2279 - val_loss: 0.2565\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 37us/step - loss: 0.2262 - val_loss: 0.2605\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2271 - val_loss: 0.2598\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2260 - val_loss: 0.2582\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2262 - val_loss: 0.2588\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 50us/step - loss: 0.2256 - val_loss: 0.2579\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2249 - val_loss: 0.2579\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2249 - val_loss: 0.2609\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2243 - val_loss: 0.2592\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2243 - val_loss: 0.2613\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2236 - val_loss: 0.2598\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2230 - val_loss: 0.2587\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2234 - val_loss: 0.2581\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2232 - val_loss: 0.2597\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2226 - val_loss: 0.2620\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2227 - val_loss: 0.2565\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2224 - val_loss: 0.2643\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2222 - val_loss: 0.2627\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2219 - val_loss: 0.2637\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2217 - val_loss: 0.2636\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2216 - val_loss: 0.2650\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2210 - val_loss: 0.2573\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2216 - val_loss: 0.2602\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2217 - val_loss: 0.2602\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2213 - val_loss: 0.2656\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2212 - val_loss: 0.2635\n",
      "1973/1973 [==============================] - 0s 25us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 228us/step - loss: 0.4094 - val_loss: 0.3501\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.3178 - val_loss: 0.3061\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2824 - val_loss: 0.2868\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2655 - val_loss: 0.2802\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2566 - val_loss: 0.2772\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2513 - val_loss: 0.2750\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2482 - val_loss: 0.2712\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2459 - val_loss: 0.2696\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2438 - val_loss: 0.2727\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2424 - val_loss: 0.2674\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2420 - val_loss: 0.2706\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2403 - val_loss: 0.2682\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2396 - val_loss: 0.2682\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2392 - val_loss: 0.2686\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2379 - val_loss: 0.2710\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2376 - val_loss: 0.2658\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2368 - val_loss: 0.2651\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2365 - val_loss: 0.2654\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2352 - val_loss: 0.2662\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2348 - val_loss: 0.2657\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2341 - val_loss: 0.2635\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 1s 68us/step - loss: 0.2333 - val_loss: 0.2649\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2327 - val_loss: 0.2678\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2324 - val_loss: 0.2672\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2318 - val_loss: 0.2631\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2316 - val_loss: 0.2656\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2315 - val_loss: 0.2619\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2304 - val_loss: 0.2631\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2302 - val_loss: 0.2640\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2300 - val_loss: 0.2657\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2293 - val_loss: 0.2634\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2290 - val_loss: 0.2623\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2293 - val_loss: 0.2630\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2287 - val_loss: 0.2643\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2287 - val_loss: 0.2628\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2282 - val_loss: 0.2612\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2281 - val_loss: 0.2606\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2279 - val_loss: 0.2634\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2270 - val_loss: 0.2622\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2272 - val_loss: 0.2620\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2268 - val_loss: 0.2660\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2259 - val_loss: 0.2623\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 1s 66us/step - loss: 0.2261 - val_loss: 0.2664\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2250 - val_loss: 0.2628\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2254 - val_loss: 0.2613\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2252 - val_loss: 0.2617\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2249 - val_loss: 0.2620\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2247 - val_loss: 0.2620\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2248 - val_loss: 0.2624\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 56us/step - loss: 0.2243 - val_loss: 0.2634\n",
      "1973/1973 [==============================] - 0s 29us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 241us/step - loss: 0.4888 - val_loss: 0.3944\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.3335 - val_loss: 0.3132\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2752 - val_loss: 0.2918\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2589 - val_loss: 0.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2517 - val_loss: 0.2792\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2474 - val_loss: 0.2746\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2437 - val_loss: 0.2759\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2408 - val_loss: 0.2732\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2391 - val_loss: 0.2741\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2375 - val_loss: 0.2721\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2367 - val_loss: 0.2673\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2354 - val_loss: 0.2686\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2346 - val_loss: 0.2657\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2341 - val_loss: 0.2665\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2335 - val_loss: 0.2661\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2332 - val_loss: 0.2662\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2322 - val_loss: 0.2633\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2313 - val_loss: 0.2688\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2307 - val_loss: 0.2648\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2298 - val_loss: 0.2647\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2292 - val_loss: 0.2649\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2286 - val_loss: 0.2651\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2280 - val_loss: 0.2617\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2279 - val_loss: 0.2675\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2272 - val_loss: 0.2642\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2266 - val_loss: 0.2629\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2264 - val_loss: 0.2665\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2265 - val_loss: 0.2595\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2256 - val_loss: 0.2653\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2257 - val_loss: 0.2648\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2246 - val_loss: 0.2683\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2247 - val_loss: 0.2648\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2247 - val_loss: 0.2635\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2249 - val_loss: 0.2611\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2239 - val_loss: 0.2627\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2235 - val_loss: 0.2648\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 1s 65us/step - loss: 0.2229 - val_loss: 0.2609\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2236 - val_loss: 0.2638\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2222 - val_loss: 0.2614\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2222 - val_loss: 0.2612\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2223 - val_loss: 0.2645\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2228 - val_loss: 0.2606\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2216 - val_loss: 0.2615\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2210 - val_loss: 0.2729\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2217 - val_loss: 0.2628\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2212 - val_loss: 0.2617\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2207 - val_loss: 0.2620\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2211 - val_loss: 0.2644\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2211 - val_loss: 0.2594\n",
      "1973/1973 [==============================] - 0s 30us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 249us/step - loss: 0.3782 - val_loss: 0.3035\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2775 - val_loss: 0.2873\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2632 - val_loss: 0.2798\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2558 - val_loss: 0.2808\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2512 - val_loss: 0.2730\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2490 - val_loss: 0.2746\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2466 - val_loss: 0.2701\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2449 - val_loss: 0.2738\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2438 - val_loss: 0.2755\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2424 - val_loss: 0.2732\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2415 - val_loss: 0.2682\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2408 - val_loss: 0.2727\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2404 - val_loss: 0.2668\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2396 - val_loss: 0.2677\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2393 - val_loss: 0.2681\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2376 - val_loss: 0.2705\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2371 - val_loss: 0.2657\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2366 - val_loss: 0.2662\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2359 - val_loss: 0.2639\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2351 - val_loss: 0.2666\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2349 - val_loss: 0.2642\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2346 - val_loss: 0.2635\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2337 - val_loss: 0.2639\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2336 - val_loss: 0.2654\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2323 - val_loss: 0.2689\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2329 - val_loss: 0.2643\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2317 - val_loss: 0.2654\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2316 - val_loss: 0.2656\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2312 - val_loss: 0.2644\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2309 - val_loss: 0.2621\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 58us/step - loss: 0.2296 - val_loss: 0.2629\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2293 - val_loss: 0.2643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2290 - val_loss: 0.2628\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2289 - val_loss: 0.2614\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2285 - val_loss: 0.2672\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2274 - val_loss: 0.2616\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2278 - val_loss: 0.2634\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2268 - val_loss: 0.2623\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2256 - val_loss: 0.2666\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2251 - val_loss: 0.2636\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2250 - val_loss: 0.2580\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2248 - val_loss: 0.2595\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2240 - val_loss: 0.2668\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2245 - val_loss: 0.2633\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2233 - val_loss: 0.2660\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2230 - val_loss: 0.2638\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2232 - val_loss: 0.2644\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2228 - val_loss: 0.2687\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2229 - val_loss: 0.2624\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2221 - val_loss: 0.2640\n",
      "1973/1973 [==============================] - 0s 32us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 272us/step - loss: 0.3636 - val_loss: 0.3203\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2831 - val_loss: 0.2866\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2551 - val_loss: 0.2791\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2472 - val_loss: 0.2720\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2428 - val_loss: 0.2736\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2395 - val_loss: 0.2676\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2379 - val_loss: 0.2667\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2357 - val_loss: 0.2669\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2347 - val_loss: 0.2672\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2342 - val_loss: 0.2656\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2328 - val_loss: 0.2730\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2318 - val_loss: 0.2676\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2312 - val_loss: 0.2645\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2303 - val_loss: 0.2680\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2294 - val_loss: 0.2652\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2288 - val_loss: 0.2647\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2290 - val_loss: 0.2636\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2277 - val_loss: 0.2670\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2264 - val_loss: 0.2645\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2268 - val_loss: 0.2680\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2266 - val_loss: 0.2628\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2248 - val_loss: 0.2640\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2241 - val_loss: 0.2686\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 1s 65us/step - loss: 0.2243 - val_loss: 0.2631\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2232 - val_loss: 0.2661\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2230 - val_loss: 0.2605\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2224 - val_loss: 0.2617\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2229 - val_loss: 0.2625\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2219 - val_loss: 0.2665\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2212 - val_loss: 0.2642\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2198 - val_loss: 0.2629\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2218 - val_loss: 0.2604\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2204 - val_loss: 0.2588\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2203 - val_loss: 0.2633\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2204 - val_loss: 0.2698\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2194 - val_loss: 0.2587\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2204 - val_loss: 0.2608\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2189 - val_loss: 0.2647\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2191 - val_loss: 0.2659\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2189 - val_loss: 0.2616\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2182 - val_loss: 0.2704\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2180 - val_loss: 0.2608\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2187 - val_loss: 0.2597\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2175 - val_loss: 0.2605\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2183 - val_loss: 0.2612\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2165 - val_loss: 0.2607\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2168 - val_loss: 0.2655\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2177 - val_loss: 0.2618\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2169 - val_loss: 0.2608\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2171 - val_loss: 0.2618\n",
      "1973/1973 [==============================] - 0s 31us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 273us/step - loss: 0.4723 - val_loss: 0.3188\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2821 - val_loss: 0.2927\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2621 - val_loss: 0.2859\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 1s 66us/step - loss: 0.2533 - val_loss: 0.2784\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2461 - val_loss: 0.2731\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2422 - val_loss: 0.2747\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2387 - val_loss: 0.2696\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2352 - val_loss: 0.2738\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2341 - val_loss: 0.2660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2333 - val_loss: 0.2668\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2324 - val_loss: 0.2662\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2301 - val_loss: 0.2690\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2296 - val_loss: 0.2680\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 1s 69us/step - loss: 0.2280 - val_loss: 0.2682\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2269 - val_loss: 0.2724\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2271 - val_loss: 0.2645\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2272 - val_loss: 0.2675\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2257 - val_loss: 0.2628\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2253 - val_loss: 0.2666\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2239 - val_loss: 0.2689\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2241 - val_loss: 0.2645\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2231 - val_loss: 0.2688\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2235 - val_loss: 0.2650\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2232 - val_loss: 0.2644\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2224 - val_loss: 0.2645\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2220 - val_loss: 0.2637\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 1s 67us/step - loss: 0.2212 - val_loss: 0.2616\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 1s 68us/step - loss: 0.2220 - val_loss: 0.2666\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2202 - val_loss: 0.2673\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 1s 68us/step - loss: 0.2211 - val_loss: 0.2659\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2200 - val_loss: 0.2703\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2196 - val_loss: 0.2669\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2189 - val_loss: 0.2698\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 1s 63us/step - loss: 0.2193 - val_loss: 0.2641\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2179 - val_loss: 0.2718\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2183 - val_loss: 0.2651\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 1s 63us/step - loss: 0.2173 - val_loss: 0.2662\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2172 - val_loss: 0.2720\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2171 - val_loss: 0.2678\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2168 - val_loss: 0.2664\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2162 - val_loss: 0.2733\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2156 - val_loss: 0.2655\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2170 - val_loss: 0.2641\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2154 - val_loss: 0.2668\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2158 - val_loss: 0.2653\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2147 - val_loss: 0.2729\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2150 - val_loss: 0.2713\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 1s 63us/step - loss: 0.2144 - val_loss: 0.2649\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2138 - val_loss: 0.2646\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 63us/step - loss: 0.2133 - val_loss: 0.2674\n",
      "1973/1973 [==============================] - 0s 34us/step\n",
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 291us/step - loss: 0.3426 - val_loss: 0.2935\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2631 - val_loss: 0.2771\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2512 - val_loss: 0.2724\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2448 - val_loss: 0.2711\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2415 - val_loss: 0.2693\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 1s 65us/step - loss: 0.2392 - val_loss: 0.2695\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2368 - val_loss: 0.2647\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2371 - val_loss: 0.2640\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 60us/step - loss: 0.2358 - val_loss: 0.2662\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 48us/step - loss: 0.2342 - val_loss: 0.2635\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2334 - val_loss: 0.2644\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 49us/step - loss: 0.2323 - val_loss: 0.2626\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2312 - val_loss: 0.2646\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 1s 74us/step - loss: 0.2311 - val_loss: 0.2649\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2297 - val_loss: 0.2668\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 1s 79us/step - loss: 0.2291 - val_loss: 0.2665\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 1s 90us/step - loss: 0.2289 - val_loss: 0.2588\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 1s 70us/step - loss: 0.2270 - val_loss: 0.2664\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2272 - val_loss: 0.2629\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 50us/step - loss: 0.2257 - val_loss: 0.2615\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2258 - val_loss: 0.2581\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 1s 84us/step - loss: 0.2251 - val_loss: 0.2599\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2244 - val_loss: 0.2609\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 1s 66us/step - loss: 0.2246 - val_loss: 0.2610\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2240 - val_loss: 0.2653\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 1s 75us/step - loss: 0.2238 - val_loss: 0.2596\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2227 - val_loss: 0.2577\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 1s 64us/step - loss: 0.2234 - val_loss: 0.2649\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 49us/step - loss: 0.2232 - val_loss: 0.2631\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2212 - val_loss: 0.2614\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 1s 70us/step - loss: 0.2208 - val_loss: 0.2616\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2209 - val_loss: 0.2588\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2198 - val_loss: 0.2694\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 62us/step - loss: 0.2199 - val_loss: 0.2650\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 50us/step - loss: 0.2203 - val_loss: 0.2613\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2197 - val_loss: 0.2608\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 1s 73us/step - loss: 0.2187 - val_loss: 0.2641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 49us/step - loss: 0.2192 - val_loss: 0.2586\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 43us/step - loss: 0.2182 - val_loss: 0.2619\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 43us/step - loss: 0.2180 - val_loss: 0.2608\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2180 - val_loss: 0.2600\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 43us/step - loss: 0.2183 - val_loss: 0.2597\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 57us/step - loss: 0.2172 - val_loss: 0.2634\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 48us/step - loss: 0.2174 - val_loss: 0.2600\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 45us/step - loss: 0.2170 - val_loss: 0.2678\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 1s 66us/step - loss: 0.2164 - val_loss: 0.2693\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2162 - val_loss: 0.2680\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2171 - val_loss: 0.2641\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 0s 42us/step - loss: 0.2160 - val_loss: 0.2626\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 1s 66us/step - loss: 0.2150 - val_loss: 0.2592\n",
      "1973/1973 [==============================] - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "for first_layer in [10,20]:\n",
    "    for second_layer in [12,15]:\n",
    "        for third_layer in [3,5]:\n",
    "            model = neural_model(first_layer,second_layer,third_layer)\n",
    "            model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))\n",
    "            binary_crossentropy = model.evaluate(X_valid, y_valid)\n",
    "            result=result.append({'first_hidden':first_layer,'second_hidden':second_layer,'third_hidden':third_layer,'binary_crossentropy':binary_crossentropy},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_hidden</th>\n",
       "      <th>second_hidden</th>\n",
       "      <th>third_hidden</th>\n",
       "      <th>binary_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.261085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.263534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.263391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.259425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.261787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.267415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.259240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_hidden  second_hidden  third_hidden  binary_crossentropy\n",
       "0          10.0           12.0           3.0             0.261085\n",
       "1          10.0           12.0           5.0             0.263534\n",
       "2          10.0           15.0           3.0             0.263391\n",
       "3          10.0           15.0           5.0             0.259425\n",
       "4          20.0           12.0           3.0             0.264038\n",
       "5          20.0           12.0           5.0             0.261787\n",
       "6          20.0           15.0           3.0             0.267415\n",
       "7          20.0           15.0           5.0             0.259240"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = result['binary_crossentropy'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_best = result['first_hidden'][min_index]\n",
    "second_hidden_best = result['second_hidden'][min_index]\n",
    "third_hidden_best = result['third_hidden'][min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7891 samples, validate on 1973 samples\n",
      "Epoch 1/50\n",
      "7891/7891 [==============================] - 2s 245us/step - loss: 0.3750 - val_loss: 0.3111\n",
      "Epoch 2/50\n",
      "7891/7891 [==============================] - 0s 47us/step - loss: 0.2751 - val_loss: 0.2887\n",
      "Epoch 3/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2579 - val_loss: 0.2842\n",
      "Epoch 4/50\n",
      "7891/7891 [==============================] - 0s 38us/step - loss: 0.2500 - val_loss: 0.2741\n",
      "Epoch 5/50\n",
      "7891/7891 [==============================] - 0s 41us/step - loss: 0.2443 - val_loss: 0.2745\n",
      "Epoch 6/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2412 - val_loss: 0.2690\n",
      "Epoch 7/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2382 - val_loss: 0.2663\n",
      "Epoch 8/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2362 - val_loss: 0.2667\n",
      "Epoch 9/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2339 - val_loss: 0.2676\n",
      "Epoch 10/50\n",
      "7891/7891 [==============================] - 0s 48us/step - loss: 0.2328 - val_loss: 0.2665\n",
      "Epoch 11/50\n",
      "7891/7891 [==============================] - 0s 46us/step - loss: 0.2309 - val_loss: 0.2633\n",
      "Epoch 12/50\n",
      "7891/7891 [==============================] - 0s 45us/step - loss: 0.2303 - val_loss: 0.2661\n",
      "Epoch 13/50\n",
      "7891/7891 [==============================] - 0s 45us/step - loss: 0.2295 - val_loss: 0.2652\n",
      "Epoch 14/50\n",
      "7891/7891 [==============================] - 0s 59us/step - loss: 0.2280 - val_loss: 0.2610\n",
      "Epoch 15/50\n",
      "7891/7891 [==============================] - 1s 82us/step - loss: 0.2276 - val_loss: 0.2637\n",
      "Epoch 16/50\n",
      "7891/7891 [==============================] - 1s 77us/step - loss: 0.2268 - val_loss: 0.2678\n",
      "Epoch 17/50\n",
      "7891/7891 [==============================] - 1s 70us/step - loss: 0.2258 - val_loss: 0.2599\n",
      "Epoch 18/50\n",
      "7891/7891 [==============================] - 1s 70us/step - loss: 0.2254 - val_loss: 0.2618\n",
      "Epoch 19/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2242 - val_loss: 0.2605\n",
      "Epoch 20/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2237 - val_loss: 0.2602\n",
      "Epoch 21/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2241 - val_loss: 0.2602\n",
      "Epoch 22/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2225 - val_loss: 0.2705\n",
      "Epoch 23/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2223 - val_loss: 0.2743\n",
      "Epoch 24/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2219 - val_loss: 0.2637\n",
      "Epoch 25/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2220 - val_loss: 0.2673\n",
      "Epoch 26/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2208 - val_loss: 0.2635\n",
      "Epoch 27/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2207 - val_loss: 0.2624\n",
      "Epoch 28/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2204 - val_loss: 0.2618\n",
      "Epoch 29/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2194 - val_loss: 0.2655\n",
      "Epoch 30/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2195 - val_loss: 0.2621\n",
      "Epoch 31/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2197 - val_loss: 0.2606\n",
      "Epoch 32/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2189 - val_loss: 0.2618\n",
      "Epoch 33/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2188 - val_loss: 0.2680\n",
      "Epoch 34/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2184 - val_loss: 0.2630\n",
      "Epoch 35/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2177 - val_loss: 0.2658\n",
      "Epoch 36/50\n",
      "7891/7891 [==============================] - 0s 53us/step - loss: 0.2177 - val_loss: 0.2733\n",
      "Epoch 37/50\n",
      "7891/7891 [==============================] - 0s 55us/step - loss: 0.2182 - val_loss: 0.2687\n",
      "Epoch 38/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2175 - val_loss: 0.2637\n",
      "Epoch 39/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2170 - val_loss: 0.2701\n",
      "Epoch 40/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2174 - val_loss: 0.2678\n",
      "Epoch 41/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2178 - val_loss: 0.2644\n",
      "Epoch 42/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2165 - val_loss: 0.2705\n",
      "Epoch 43/50\n",
      "7891/7891 [==============================] - 0s 49us/step - loss: 0.2169 - val_loss: 0.2664\n",
      "Epoch 44/50\n",
      "7891/7891 [==============================] - 0s 51us/step - loss: 0.2161 - val_loss: 0.2738\n",
      "Epoch 45/50\n",
      "7891/7891 [==============================] - 0s 54us/step - loss: 0.2163 - val_loss: 0.2718\n",
      "Epoch 46/50\n",
      "7891/7891 [==============================] - 0s 52us/step - loss: 0.2156 - val_loss: 0.2683\n",
      "Epoch 47/50\n",
      "7891/7891 [==============================] - 1s 71us/step - loss: 0.2157 - val_loss: 0.2641\n",
      "Epoch 48/50\n",
      "7891/7891 [==============================] - 1s 86us/step - loss: 0.2158 - val_loss: 0.2759\n",
      "Epoch 49/50\n",
      "7891/7891 [==============================] - 1s 71us/step - loss: 0.2151 - val_loss: 0.2670\n",
      "Epoch 50/50\n",
      "7891/7891 [==============================] - 0s 61us/step - loss: 0.2151 - val_loss: 0.2692\n",
      "2466/2466 [==============================] - 0s 37us/step\n",
      "Error for the test set:  0.2667143335210919\n"
     ]
    }
   ],
   "source": [
    "first_hidden_best  = int(first_hidden_best)\n",
    "second_hidden_best = int(second_hidden_best)\n",
    "third_hidden_best  = int(third_hidden_best)\n",
    "\n",
    "min_model = neural_model(first_hidden_best,second_hidden_best,third_hidden_best)\n",
    "min_model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))\n",
    "binary_crossentropy = min_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Error for the test set: \", binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
